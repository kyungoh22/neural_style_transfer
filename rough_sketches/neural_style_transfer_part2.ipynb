{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rq1RlxkWPd8j"
      },
      "source": [
        "I've tried reproducing Andrew Ng's version (and couldn't get it to work). <br>\n",
        "Then I followed the geeks for geeks tutorial, and was able to get it to work. <br>\n",
        "Now I'll try to create an independent version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Mmp9XxfPd8k"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import sys\n",
        "import scipy.io\n",
        "import scipy.misc\n",
        "import matplotlib.pyplot as plt\n",
        "from matplotlib.pyplot import imshow\n",
        "from PIL import Image\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.python.framework.ops import EagerTensor\n",
        "import pprint\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QwQ3oHHlPd8l"
      },
      "outputs": [],
      "source": [
        "# import VGG 19 model and keras Model API\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r4GcSkmOPd8l"
      },
      "source": [
        "<h3> Load images </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K9WvyVV9Pd8l"
      },
      "source": [
        "<h5> Load content image </h5>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "K6hjKyCCPd8l",
        "outputId": "1469d9d4-edc1-496c-d271-04e456cb3866"
      },
      "outputs": [],
      "source": [
        "img_size = 400\n",
        "content_path = \"louvre.jpg\"\n",
        "# original image is (300, 400, 3)\n",
        "\n",
        "content_image = np.array(Image.open(content_path).resize((img_size, img_size)))   # Now shape is 400, 400, 3\n",
        "content_image = np.reshape(content_image, ((1,) + content_image.shape ))                # Now (1, 400, 400, 3)                \n",
        "content_image = tf.constant(content_image)    # Convert to tensor\n",
        "\n",
        "print(content_image.shape)\n",
        "imshow(content_image[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "r1MO8TS8Pd8r"
      },
      "source": [
        "<h5> Load style image </h5>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 287
        },
        "id": "2SHUadY0Pd8s",
        "outputId": "55fc5067-b2a8-4a18-a211-dcc013a88526"
      },
      "outputs": [],
      "source": [
        "# original image once again (300, 400, 3)\n",
        "\n",
        "style_path = \"van_gogh.jpg\"\n",
        "\n",
        "style_image = np.array(Image.open(style_path).resize((img_size, img_size)))\n",
        "style_image = tf.constant(np.reshape(style_image, ((1,) + style_image.shape)))\n",
        "\n",
        "print(style_image.shape)\n",
        "imshow(style_image[0])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mv6I4utDPd8s"
      },
      "source": [
        "<h5> Preprocess images </h5>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YHyaBtZOPd8s"
      },
      "outputs": [],
      "source": [
        "# Convert the values in content_image to float32 types between 0 and 1. Then save as tf Variable.\n",
        "preprocessed_content = tf.Variable (tf.image.convert_image_dtype(content_image, tf.float32))        # (1, img_size, img_size, 3)\n",
        "\n",
        "# Convert the values in style_image to float32 types between 0 and 1. Then save as tf Variable.\n",
        "preprocessed_style = tf.Variable (tf.image.convert_image_dtype(style_image, tf.float32))            # (1, img_size, img_size, 3)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IZs98V_3Pd8s"
      },
      "source": [
        "<h3> Load model </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_NFmZ6QPd8s",
        "outputId": "3eefde01-5491-435e-f4ae-071cbc384fb5"
      },
      "outputs": [],
      "source": [
        "vgg_model = VGG19(\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "# Freeze weights\n",
        "vgg_model.trainable = False\n",
        " \n",
        "for layer in vgg_model.layers:\n",
        "    print(layer.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fAyva31tPd8s"
      },
      "outputs": [],
      "source": [
        "# For the content layer, we will use 'block5_conv4' \n",
        "# For the style layers, we will use ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IWtkzxjbPd8t",
        "outputId": "655e568c-4efc-48eb-8dcb-b402d0c719cd"
      },
      "outputs": [],
      "source": [
        "vgg_model.input, vgg_model.get_layer('block1_conv1').output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9qbhPlkPd8t"
      },
      "outputs": [],
      "source": [
        "content_layer = 'block5_conv4'\n",
        "style_layers = ['block1_conv1', 'block2_conv1', 'block3_conv1', 'block4_conv1', 'block5_conv1']\n",
        "\n",
        "content_model = Model(inputs = vgg_model.input, outputs = vgg_model.get_layer(content_layer).output)\n",
        "style_models = [Model(inputs = vgg_model.input, outputs = vgg_model.get_layer(style_layer).output) for style_layer in style_layers]\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d7nZjpm1Pd8t"
      },
      "source": [
        "<h3> Cost functions </h3>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Uan3eTjwPd8t"
      },
      "source": [
        "<h5> 1) Content Cost </h5>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5B_yHQnDPd8t"
      },
      "outputs": [],
      "source": [
        "def content_cost (content, generated):\n",
        "    \"\"\"\n",
        "    content, generated = 4D tensors\n",
        "    \"\"\"\n",
        "    n_H, n_W, n_C = content[0].shape                    # content = (1,400,400,3)\n",
        "    a_C = content_model(content)[0]\n",
        "    a_G = content_model (generated)[0]\n",
        "    content_cost = (1/(4*n_H*n_W*n_C))* tf.reduce_sum(tf.square(tf.subtract(a_C, a_G)))\n",
        "    return content_cost"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lZwo9BKePd8t"
      },
      "source": [
        "<h5> 2) Style Cost </h5>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UZQcCAcPd8t"
      },
      "outputs": [],
      "source": [
        "def gram_matrix (A):\n",
        "    gram = tf.linalg.matmul(A, tf.transpose(A))\n",
        "    return gram\n",
        "\n",
        "def style_cost(style_image, generated_image, style_weights = [0.2, 0.2, 0.2, 0.2, 0.2]):\n",
        "\n",
        "    \"\"\"\n",
        "    inputs\n",
        "    style_image = preprocessed_image, 4D tensor (1, n_H, n_W, n_C), with values from 0 to 1\n",
        "\n",
        "    return\n",
        "    total cost\n",
        "    \"\"\"\n",
        "\n",
        "    J_style_total = 0\n",
        "\n",
        "    for i, style_model in enumerate(style_models):\n",
        "        a_S = style_model(style_image)[0]       # a_S = (n_H, n_W, n_C)\n",
        "        a_G = style_model(generated_image)[0]   # a_G = (n_H, n_W, n_C)\n",
        "\n",
        "        n_H, n_W, n_C = a_S.shape\n",
        "        \n",
        "        # Reshape the images from (n_H * n_W, n_C) to have them of shape (n_C, n_H * n_W)\n",
        "        a_S = tf.reshape(a_S, shape = [n_H * n_W, n_C])\n",
        "        a_S = tf.transpose(a_S, perm = [1,0])   # a_S = (n_C, n_H * n_W)\n",
        "\n",
        "        a_G = tf.reshape(a_G, shape = [n_H * n_W, n_C])\n",
        "        a_G = tf.transpose(a_G, perm = [1,0])   # a_G = (n_C, n_H * n_W)\n",
        "\n",
        "        # Compute gram_matrices for both images S and G \n",
        "        GS = gram_matrix(a_S)\n",
        "        GG = gram_matrix(a_G)\n",
        "\n",
        "        # Compute style cost for current layer\n",
        "        J_style_layer = (1/(4*n_C*n_C*(n_H*n_W)**2)) * tf.reduce_sum(tf.multiply(tf.subtract(GS, GG), tf.subtract(GS, GG)))\n",
        "\n",
        "        # Update total\n",
        "\n",
        "        J_style_total += style_weights[i]*J_style_layer\n",
        "\n",
        "    return J_style_total\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D_-g_tj5Pd8u"
      },
      "source": [
        "<h3> Necessary Post-processing Functions </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eVI2cXxxPd8u"
      },
      "outputs": [],
      "source": [
        "def clip_0_1(image):\n",
        "    \"\"\"\n",
        "    Truncate all the pixels in the tensor to be between 0 and 1\n",
        "    During optimisation, we want to make sure the updated pixel values for the image stay within the range 0 to 1.\n",
        "\n",
        "    Returns:\n",
        "    Tensor\n",
        "    \"\"\"\n",
        "    return tf.clip_by_value(image, clip_value_min=0.0, clip_value_max=1.0)\n",
        "\n",
        "def tensor_to_image(tensor):\n",
        "    \"\"\"\n",
        "    Scales the tensor values (input values are between 0 and 1) back to range of 0 to 255.\n",
        "    Also convert the values into integers.\n",
        "    If tensor is 4D, then take only last 3 values.\n",
        "    Convert this to PIL image.\n",
        "    \n",
        "    Arguments:\n",
        "    tensor -- Tensor\n",
        "    \n",
        "    Returns:\n",
        "    Image: A PIL image\n",
        "    \"\"\"\n",
        "    tensor = tensor * 255                       # Convert values to range 0–255\n",
        "    tensor = np.array(tensor, dtype=np.uint8)   # Convert into integer type\n",
        "    if np.ndim(tensor) > 3:                     # If more than 3 dimensions, take only last 3 dimensions.\n",
        "        assert tensor.shape[0] == 1\n",
        "        tensor = tensor[0]\n",
        "    return Image.fromarray(tensor)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uth9FkBVPd8u"
      },
      "source": [
        "<h3> Optimise </h3>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BntepKGtPd8u",
        "outputId": "f8f455a7-6096-41ad-ac6b-400ba725c97b"
      },
      "outputs": [],
      "source": [
        "type(preprocessed_content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dtwUIpYzPd8u",
        "outputId": "6c93f138-fc49-44ca-adb7-7c11dc21d123"
      },
      "outputs": [],
      "source": [
        "content = tf.identity(preprocessed_content)\n",
        "style = tf.identity(preprocessed_style)\n",
        "generated = tf.Variable(tf.identity(content))\n",
        "\n",
        "opt = tf.keras.optimizers.Adam(learning_rate=0.01)  \n",
        "\n",
        "with tf.GradientTape() as tape:\n",
        "    J_content = content_cost(content, generated)\n",
        "    J_style = style_cost(style, generated)\n",
        "    J_total = 10 * J_content + 1000 * J_style\n",
        "\n",
        "grads = tape.gradient(J_total, generated)           # J_total is y, generated is x; \n",
        "print (content[0,0,0], generated[0,0,0])\n",
        "opt.apply_gradients([(grads, generated)])\n",
        "print(content[0,0,0], generated[0,0,0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wXUb9iLUPd8v",
        "outputId": "f7042ec2-1568-4560-fdef-7bf9902b7d04"
      },
      "outputs": [],
      "source": [
        "content [0,0,0], preprocessed_content[0,0,0]\n",
        "content = content + 1\n",
        "content [0,0,0], preprocessed_content[0,0,0]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "J9dCeWt0Pd8v"
      },
      "outputs": [],
      "source": [
        "generated_images = []\n",
        "def training_loop(preprocessed_content, preprocessed_style, iterations=500, a=10, b=1000, learning_rate = 0.1):\n",
        "    # Notice that the weight for the style error is way bigger. Compensates for not adding noise to initial generated image.\n",
        "    \n",
        "    # load content and style images from their respective path\n",
        "    content = tf.identity(preprocessed_content)         # use tf.identity to create deep copy\n",
        "    style = tf.identity(preprocessed_style)\n",
        "    generated = tf.Variable(tf.identity(content))       # use tf.Variable since \"generated\" will be updated\n",
        " \n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)  \n",
        " \n",
        "    best_cost = 1000000000000000             # set to a huge number (original had \"Inf\")\n",
        "    best_image = None\n",
        "    for i in range(iterations):\n",
        "        \n",
        "        with tf.GradientTape() as tape:\n",
        "            J_content = content_cost(content, generated)\n",
        "            J_style = style_cost(style, generated)\n",
        "            J_total = a * J_content + b * J_style\n",
        " \n",
        "        grads = tape.gradient(J_total, generated)           # J_total is y, generated is x; \n",
        "        opt.apply_gradients([(grads, generated)])           # optimise x so as to minimise y.\n",
        "        generated.assign(clip_0_1(generated))\n",
        "\n",
        "        generated_images.append(generated)\n",
        "\n",
        "        if J_total < best_cost:\n",
        "            best_cost = J_total\n",
        "            best_image = generated\n",
        "        \n",
        "        if i%1000==0:\n",
        "            image = tensor_to_image(best_image)\n",
        "            print(f'Iteration: {i}')\n",
        "            print(f'Total Loss: {J_total}')\n",
        "            imshow(image)\n",
        "            plt.show()\n",
        "\n",
        "    \n",
        "    best_image = tensor_to_image(best_image)                # Convert format of image (currently a tensor) ot image\n",
        " \n",
        "    return best_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 305
        },
        "id": "U08BUsVbPd8v",
        "outputId": "cb5d3fdf-aa1b-4008-e2ce-a9540d27c2e0"
      },
      "outputs": [],
      "source": [
        "best_image1 = training_loop(preprocessed_content, preprocessed_style, iterations=100, a=10, b=1000, learning_rate = 0.07)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "Rixb73wJ2m6R",
        "outputId": "35c1cead-19b4-42ac-e195-867c59e6d8ea"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3,figsize = (12,6), dpi = 300)\n",
        "ax[0].imshow(content_image[0])\n",
        "ax[0].set_title('Content image')\n",
        "ax[1].imshow(style_image[0])\n",
        "ax[1].set_title('Style image')\n",
        "ax[2].imshow(best_image1)\n",
        "ax[2].set_title('Generated image v1')\n",
        "ax[2].set_xlabel('iterations: 100\\n a: 10\\n b: 1000\\n learning_rate: 0.07')\n",
        "plt.tight_layout()\n",
        "plt.savefig('generated_image_v1.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "c5nRGQhWb7-x",
        "outputId": "14ecf32e-1f95-4e4d-c257-b69e89770b8f"
      },
      "outputs": [],
      "source": [
        "best_image2 = training_loop(preprocessed_content, preprocessed_style, iterations=1000, a=10, b=100, learning_rate = 0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "PdwirMiVcKwQ",
        "outputId": "46cdee0e-9bb5-4aea-977e-1ebeec283563"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3,figsize = (12,6), dpi = 300)\n",
        "ax[0].imshow(content_image[0])\n",
        "ax[0].set_title('Content image')\n",
        "ax[1].imshow(style_image[0])\n",
        "ax[1].set_title('Style image')\n",
        "ax[2].imshow(best_image2)\n",
        "ax[2].set_title('Generated image v2')\n",
        "ax[2].set_xlabel('iterations: 1000\\n a: 10\\n b: 100\\n learning_rate: 0.05')\n",
        "plt.tight_layout()\n",
        "plt.savefig('generated_image_v2.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zPW7XMRFtdEW",
        "outputId": "89184980-32ab-4281-c065-59e9295df498"
      },
      "outputs": [],
      "source": [
        "best_image3 = training_loop(preprocessed_content, preprocessed_style, iterations=10000, a=10, b=100, learning_rate = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "jiGxQog3txTw",
        "outputId": "80d2bf0e-aa99-4200-d2c8-6055dd31b6e6"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3,figsize = (12,6), dpi = 300)\n",
        "ax[0].imshow(content_image[0])\n",
        "ax[0].set_title('Content image')\n",
        "ax[1].imshow(style_image[0])\n",
        "ax[1].set_title('Style image')\n",
        "ax[2].imshow(best_image3)\n",
        "ax[2].set_title('Generated image v3')\n",
        "ax[2].set_xlabel('iterations: 10,000\\n a: 10\\n b: 100\\n learning_rate: 0.001')\n",
        "plt.tight_layout()\n",
        "plt.savefig('generated_image_v3.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "a9uRf_bLAXGh",
        "outputId": "662e26c5-5742-4bb7-e372-f27a040cca7e"
      },
      "outputs": [],
      "source": [
        "best_image4 = training_loop(preprocessed_content, preprocessed_style, iterations=15000, a=10, b=300, learning_rate = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "MqVMKA_dA7nQ",
        "outputId": "6d8e8853-3b21-481c-a062-ee8918c5bfb9"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3,figsize = (12,6), dpi = 300)\n",
        "ax[0].imshow(content_image[0])\n",
        "ax[0].set_title('Content image')\n",
        "ax[1].imshow(style_image[0])\n",
        "ax[1].set_title('Style image')\n",
        "ax[2].imshow(best_image4)\n",
        "ax[2].set_title('Generated image v4')\n",
        "ax[2].set_xlabel('iterations: 15,000\\n a: 10\\n b: 300\\n learning_rate: 0.001')\n",
        "plt.tight_layout()\n",
        "plt.savefig('generated_image_v4.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "T3NeQb3nU2sA",
        "outputId": "86aabdcd-5f4a-4d55-ebba-8bddd8eaeba9"
      },
      "outputs": [],
      "source": [
        "best_image5 = training_loop(preprocessed_content, preprocessed_style, iterations=25000, a=10, b=1000, learning_rate = 0.001)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 560
        },
        "id": "R1abpqg5VDfc",
        "outputId": "9b5f40f7-0587-444d-cd35-9986a4ec297d"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,3,figsize = (12,6), dpi = 300)\n",
        "ax[0].imshow(content_image[0])\n",
        "ax[0].set_title('Content image')\n",
        "ax[1].imshow(style_image[0])\n",
        "ax[1].set_title('Style image')\n",
        "ax[2].imshow(best_image5)\n",
        "ax[2].set_title('Generated image v5')\n",
        "ax[2].set_xlabel('iterations: 25,000\\n a: 10\\n b: 1000\\n learning_rate: 0.001')\n",
        "plt.tight_layout()\n",
        "plt.savefig('generated_image_v5.jpg')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "Os-Vibbm0Sk0",
        "outputId": "0a22ad9b-3842-44ea-ec64-f4cf5b2ee802"
      },
      "outputs": [],
      "source": [
        "fig, ax = plt.subplots(1,5, figsize = (20,5), dpi = 150)\n",
        "ax[0].imshow(best_image1)\n",
        "ax[1].imshow(best_image2)\n",
        "ax[2].imshow(best_image3)\n",
        "ax[3].imshow(best_image4)\n",
        "ax[4].imshow(best_image5)\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I8e7Vw9e02t5"
      },
      "outputs": [],
      "source": [
        "best_image1.save(\"just_generated_image_v1.jpg\")\n",
        "best_image2.save(\"just_generated_image_v2.jpg\")\n",
        "best_image3.save(\"just_generated_image_v3.jpg\")\n",
        "best_image4.save(\"just_generated_image_v4.jpg\")\n",
        "best_image5.save(\"just_generated_image_v5.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ebONGQGt66u4"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "neural_style_transfer_part2.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('deep_learning')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "orig_nbformat": 4,
    "vscode": {
      "interpreter": {
        "hash": "62f0de500e91648e2f1c8ecd59ca95f97588cc062e27f09a44618e0428f97b74"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
