{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViUw-9Wml2bU"
      },
      "outputs": [],
      "source": [
        "# import numpy, tensorflow and matplotlib\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import copy\n",
        " \n",
        "# import VGG 19 model and keras Model API\n",
        "from tensorflow.keras.applications.vgg19 import VGG19, preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import load_img, img_to_array\n",
        "from tensorflow.keras.models import Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aj2PNIKcl7E3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Image Credits: Tensorflow Doc\n",
        "content_path = tf.keras.utils.get_file('content.jpg',\n",
        "                                       'https://storage.googleapis.com/download.tensorflow.org/example_images/YellowLabradorLooking_new.jpg')\n",
        "style_path = tf.keras.utils.get_file('style.jpg',\n",
        "                                     'https://storage.googleapis.com/download.tensorflow.org/example_images/Vassily_Kandinsky%2C_1913_-_Composition_7.jpg')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jELoVga9l8gw",
        "outputId": "f2eba11e-a02f-4c88-fcf0-d8c354530bb3"
      },
      "outputs": [],
      "source": [
        "# code\n",
        "# this function download the VGG model and initialise it\n",
        "model = VGG19(\n",
        "    include_top=False,\n",
        "    weights='imagenet'\n",
        ")\n",
        "# set training to False\n",
        "model.trainable = False\n",
        "# Print details of different layers\n",
        " \n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f45P-RSal9rJ"
      },
      "outputs": [],
      "source": [
        "# code to load and process image\n",
        "def load_and_process_image(image_path):\n",
        "    img = load_img(image_path)\n",
        "    # convert image to array\n",
        "    img = img_to_array(img)\n",
        "    img = preprocess_input(img)\n",
        "\n",
        "    # From tensorflow docks, regarding vgg19.preprocess_input():\n",
        "    # The images are converted from RGB to BGR, then each color channel \n",
        "    # is zero-centered with respect to the ImageNet dataset, without scaling.\n",
        "\n",
        "    img = np.expand_dims(img, axis=0)\n",
        "    return img"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_kP4vT5Ll_7G"
      },
      "outputs": [],
      "source": [
        "# Now, we define the deprocess function that takes the input image and perform \n",
        "# the inverse of preprocess_input function that we imported above. \n",
        "# To display the unprocessed image, we also define a display function.\n",
        "\n",
        "def deprocess(img):\n",
        "    # perform the inverse of the pre processing step\n",
        "    \n",
        "    temp = copy.deepcopy(img)\n",
        "    temp[:, :, 0] += 103.939\n",
        "    temp[:, :, 1] += 116.779\n",
        "    temp[:, :, 2] += 123.68\n",
        "    # convert RGB to BGR\n",
        "    temp = temp[:, :, ::-1]\n",
        " \n",
        "    temp = np.clip(temp, 0, 255).astype('uint8')\n",
        "    return temp\n",
        " \n",
        " \n",
        "def display_image(image):\n",
        "    # remove one dimension if image has 4 dimension\n",
        "    if len(image.shape) == 4:\n",
        "        img = np.squeeze(image, axis=0)\n",
        " \n",
        "    img = deprocess(img)\n",
        " \n",
        "    plt.grid(False)\n",
        "    plt.xticks([])\n",
        "    plt.yticks([])\n",
        "    plt.imshow(img)\n",
        "    return"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "7PNTamDNmBwH",
        "outputId": "fffbe93c-842a-4e6b-ce5b-659812a927b8"
      },
      "outputs": [],
      "source": [
        "# load content image\n",
        "content_img = load_and_process_image(content_path)\n",
        "display_image(content_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZGPcgKcNC618",
        "outputId": "de67f834-22d3-462b-db58-715586dce098"
      },
      "outputs": [],
      "source": [
        "content_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "KbPR-WPemDSW",
        "outputId": "802d54b7-dd71-4638-e068-1943eb47910f"
      },
      "outputs": [],
      "source": [
        "# load style image\n",
        "style_img = load_and_process_image(style_path)\n",
        "display_image(style_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vT8kFrbzEdTu",
        "outputId": "1e99374c-df81-4437-d723-24ce5581620e"
      },
      "outputs": [],
      "source": [
        "style_img.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PTOq_CJ-mEdf",
        "outputId": "47151f73-414c-4019-9375-f95cf9caa749"
      },
      "outputs": [],
      "source": [
        "\n",
        "# define content model\n",
        "content_layer = 'block5_conv2'\n",
        "content_model = Model(\n",
        "    inputs=model.input,\n",
        "    outputs=model.get_layer(content_layer).output\n",
        ")\n",
        "content_model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "QnFwRecFmFpM"
      },
      "outputs": [],
      "source": [
        "# define style model\n",
        "style_layers = [\n",
        "    'block1_conv1',\n",
        "    'block3_conv1',\n",
        "    'block5_conv1'\n",
        "]\n",
        "style_models = [Model(inputs=model.input,\n",
        "                      outputs=model.get_layer(layer).output) for layer in style_layers]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rgESYPLRmHX7"
      },
      "outputs": [],
      "source": [
        "# Content loss\n",
        "def content_cost(content, generated):\n",
        "    a_C = content_model(content)\n",
        "    a_G = content_model(generated)                      # This line was missing in the tutorial.\n",
        "    loss = tf.reduce_mean(tf.square(a_C - a_G))\n",
        "    return loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5fEBjjDzmIXA"
      },
      "outputs": [],
      "source": [
        "# gram matrix\n",
        "def gram_matrix(A):\n",
        "    channels = int(A.shape[-1])\n",
        "    a = tf.reshape(A, [-1, channels])       # a = (n_H * n_W, n_C)\n",
        "    n = tf.shape(a)[0]                      # n = number of elements per row of a\n",
        "    gram = tf.matmul(a, a, transpose_a=True)\n",
        "    return gram / tf.cast(n, tf.float32)    # normalise\n",
        " \n",
        " \n",
        "weight_of_layer = 1. / len(style_models)\n",
        " \n",
        " \n",
        "# style loss\n",
        "def style_cost(style, generated):\n",
        "    J_style = 0\n",
        " \n",
        "    for style_model in style_models:\n",
        "        a_S = style_model(style)\n",
        "        a_G = style_model(generated)\n",
        "        GS = gram_matrix(a_S)\n",
        "        GG = gram_matrix(a_G)\n",
        "        current_cost = tf.reduce_mean(tf.square(GS - GG))\n",
        "        J_style += current_cost * weight_of_layer               # weight_of_layer undefined at this point\n",
        " \n",
        "    return J_style"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CA11ny3smJhh"
      },
      "outputs": [],
      "source": [
        "# training function\n",
        "generated_images = []\n",
        " \n",
        "def training_loop(content_path, style_path, iterations=500, a=10, b=1000, learning_rate = 10):\n",
        "    # Notice that the weight for the style error is way bigger. This probably to compensate for not adding noise to initial generated image.\n",
        "    \n",
        "    # load content and style images from their respective path\n",
        "    content = load_and_process_image(content_path)\n",
        "    style = load_and_process_image(style_path)\n",
        "    generated = tf.Variable(content, dtype=tf.float32)\n",
        " \n",
        "    opt = tf.keras.optimizers.Adam(learning_rate=learning_rate)     # learning_rate of 7 seems crazy high. Come back and change to something like 0.1\n",
        " \n",
        "    best_cost = 1000000000000000             # set to a huge number (original had \"Inf\")\n",
        "    best_image = None\n",
        "    for i in range(iterations):\n",
        "        #% % time\n",
        "        with tf.GradientTape() as tape:\n",
        "            J_content = content_cost(content, generated)\n",
        "            J_style = style_cost(style, generated)\n",
        "            J_total = a * J_content + b * J_style\n",
        " \n",
        "        grads = tape.gradient(J_total, generated)           # J_total is y, generated is x; \n",
        "        opt.apply_gradients([(grads, generated)])           # optimise x so as to minimise y.\n",
        " \n",
        "        if J_total < best_cost:\n",
        "            best_cost = J_total\n",
        "            best_image = generated.numpy()\n",
        " \n",
        "        print(\"Iteration :{}\".format(i))\n",
        "        print('Total Loss {:e}.'.format(J_total))\n",
        "        generated_images.append(generated.numpy())\n",
        " \n",
        "    return best_image"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8TPC9KlcmK_H",
        "outputId": "8604d72f-3795-4b26-dc17-de2e0f2a09e3"
      },
      "outputs": [],
      "source": [
        "\n",
        "# Train the model and get best image\n",
        "final_img = training_loop(content_path, style_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GAr7I4D44lVz"
      },
      "outputs": [],
      "source": [
        "# with learning rate of 10, total loss goes down to 2.2e+08, and then oscillates, sometimes all the way up to 6e+08"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "jM6PPZMMoAvo",
        "outputId": "4184e369-0c13-433c-d6c0-33639932f1e9"
      },
      "outputs": [],
      "source": [
        "# plot best result\n",
        "display_image(final_img)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r0Tv7r6c5OQi"
      },
      "outputs": [],
      "source": [
        "# result is definitely much better than before"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YijW3LPtuO5L",
        "outputId": "d7abfb45-d1fa-4a25-cfe4-66e66bafc2a7"
      },
      "outputs": [],
      "source": [
        "final_img2 = training_loop(content_path, style_path, iterations = 500, learning_rate = 3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "Aa-TjRZk5k-m",
        "outputId": "29d15313-835e-472c-a205-82001522be64"
      },
      "outputs": [],
      "source": [
        "# plot best result\n",
        "display_image(final_img2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DrfqYmSEi6P",
        "outputId": "3e574f17-1631-45b2-9429-a1e511c2023b"
      },
      "outputs": [],
      "source": [
        "final_img2 = training_loop(content_path, style_path, iterations = 700, learning_rate = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "tEGXI80B8VhC",
        "outputId": "33fd2722-4b38-4961-a626-97f67a03eee1"
      },
      "outputs": [],
      "source": [
        "display_image(final_img2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B3xdJsThIfzF",
        "outputId": "9ff7b879-17be-4336-bb44-29ef7aaca604"
      },
      "outputs": [],
      "source": [
        "final_img3 = training_loop(content_path, style_path, iterations = 1100, learning_rate = 5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 252
        },
        "id": "sXYEghKZI8ft",
        "outputId": "c3484f2e-307a-4bf1-fa59-772170f84c56"
      },
      "outputs": [],
      "source": [
        "display_image(final_img3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "m258E_38O1pf"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "neural_style_transfer_geeks_for_geeks.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3.9.13 ('deep_learning')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "62f0de500e91648e2f1c8ecd59ca95f97588cc062e27f09a44618e0428f97b74"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
